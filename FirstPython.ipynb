{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FirstPython.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "djfaMpQI05gz",
        "1BcKXXVm3pXn"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfJx29wuzTJE",
        "colab_type": "text"
      },
      "source": [
        "# **Imports and settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3AnEfbshjQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from shutil import copyfile\n",
        "from shutil import rmtree\n",
        "import logging\n",
        "import json\n",
        "import math\n",
        "from datetime import datetime\n",
        "\n",
        "from more_itertools import sliced\n",
        "from random import randint\n",
        "from random import choices\n",
        "import random\n",
        "from google.cloud import storage\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split  \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=\"tracker.log\", level=logging.DEBUG, filemode=\"w\")\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"activitytracker-bde5c-firebase-adminsdk-ks82x-ad642b2476.json\"\n",
        "client = storage.Client()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH3laz0dz88Z",
        "colab_type": "text"
      },
      "source": [
        "# **Data Types**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg5ogUj1A9Iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Motion:\n",
        "    def __init__(self, name: str, tag: str):\n",
        "        self.name = name\n",
        "        self.tag = tag\n",
        "\n",
        "\n",
        "class Data:\n",
        "    def __init__(self, dict_json: dict):\n",
        "        self.fileName = dict_json['fileName']\n",
        "        self.motion = dict_json['motion']\n",
        "        self.time = dict_json['time']\n",
        "        self.userName = dict_json['userName']\n",
        "        self.listX = []\n",
        "        self.listY = []\n",
        "        self.listZ = []\n",
        "        \n",
        "        for idx, val in enumerate(dict_json['graphList']):\n",
        "            if idx % 3 == 0:\n",
        "                self.listX.append(val)\n",
        "            if idx % 3 == 1:\n",
        "                self.listY.append(val)\n",
        "            if idx % 3 == 2:\n",
        "                self.listZ.append(val)\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.fileName\n",
        "\n",
        "class ParsedData:\n",
        "    def __init__(self, dict_json: dict):\n",
        "        self.fileName = dict_json['fileName']\n",
        "        self.motion = dict_json['motion']\n",
        "        self.time = dict_json['time']\n",
        "        self.userName = dict_json['userName']\n",
        "        self.listX = dict_json['listX']\n",
        "        self.listY = dict_json['listY']\n",
        "        self.listZ = dict_json['listZ']\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.fileName     \n",
        "      \n",
        "class CroppedData:\n",
        "    def __init__(self, file_name, motion, time, user_name, list_x, list_y, list_z):\n",
        "        self.fileName = file_name\n",
        "        self.motion = motion\n",
        "        self.time = time\n",
        "        self.userName = user_name\n",
        "        self.listX = list_x\n",
        "        self.listY = list_y\n",
        "        self.listZ = list_z\n",
        "        \n",
        "    def __str__(self):\n",
        "        return self.fileName\n",
        "\n",
        "class MarkedData:\n",
        "    def __init__(self, file_name, motion, time, user_name, list_x, list_y, list_z, steps):\n",
        "        self.fileName = file_name\n",
        "        self.motion = motion\n",
        "        self.time = time\n",
        "        self.userName = user_name\n",
        "        self.listX = list_x\n",
        "        self.listY = list_y\n",
        "        self.listZ = list_z\n",
        "        self.steps = steps\n",
        "        \n",
        "    def __str__(self):\n",
        "        return self.fileName"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7waZGHvzqz5",
        "colab_type": "text"
      },
      "source": [
        "# **Create directories and file list**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "849xpz4TD5GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_folder(folder: str):\n",
        "  if not os.path.exists(folder):\n",
        "    os.makedirs(folder)\n",
        "    logging.debug(f\"A directory {folder} has been created.\")\n",
        "\n",
        "    \n",
        "def create_folders(folders: list):\n",
        "  for folder in folders:\n",
        "    create_folder(folder)\n",
        "    \n",
        "\n",
        "def list_local_files(folder: str) -> list:\n",
        "  files = [f\"{folder}/\" + file for file in os.listdir(folder)]\n",
        "  random.shuffle(files)\n",
        "  return files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8IHjXL4zvON",
        "colab_type": "text"
      },
      "source": [
        "# **FireBase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv7Z5vF9Bpge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_blobs(bucket_name: str, blob_prefix: str = None, delimiter: str = None) -> list:\n",
        "    \"\"\"\n",
        "    This function returns a list of all files in FireBase. This will be needed to download files.\n",
        "    :param bucket_name: This is the name of the repository with such ending appspot.com\n",
        "    :param blob_prefix: Directory Name\n",
        "    :param delimiter: No, youâ€™ll understand it yourself. This is a separator\n",
        "    :return: List<Blob> with fields for each blob: name, id, bucket_name\n",
        "    \"\"\"\n",
        "\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs(prefix=blob_prefix, delimiter=delimiter)\n",
        "    return [blob for blob in blobs]\n",
        "\n",
        "\n",
        "def download_blobs(blobs: list, folder: str):\n",
        "    \"\"\"\n",
        "    This function downloads each blob from the blobs list to the specified directory.\n",
        "    :param blobs: List of storage.Blob\n",
        "    :param folder: Path to save blobs(json)\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "\n",
        "    create_folder(folder)\n",
        "\n",
        "    for blob in blobs:\n",
        "        destination_uri = f\"{folder}/{blob.name.split('/')[1]}\"\n",
        "        blob.download_to_filename(destination_uri)\n",
        "        logging.debug(f\"The file ({blob.name}) has been downloaded to the {folder}.\")\n",
        "\n",
        "\n",
        "def upload_blob(bucket_name: str, file_path, file_name: str, folder_path: str):\n",
        "    \"\"\"\n",
        "    Upload the specified file to a specific folder on FireBase.\n",
        "    :param bucket_name: This is the name of the repository with such ending appspot.com\n",
        "    :param file_path: The path to the file to be saved.\n",
        "    :param file_name: The name of the file to be displayed in FireBase.\n",
        "    :param folder_path: The name of the folder on FireBase to which the file will be saved.\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    target_blob = bucket.blob(f\"{folder_path}/{file_name}\")\n",
        "    target_blob.upload_from_filename(file_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK-VtpN3xvNa",
        "colab_type": "text"
      },
      "source": [
        "# **Work with JSON Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0yfTiuRlZX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class to JSON file with random name\n",
        "def serialize_json(data, folder: str, file_name: str):\n",
        "    create_folder(folder)\n",
        "    purified_name = file_name.split(\"||\")[0]\n",
        "    full_name = f\"{purified_name}||{randint(10 ** 4, 10 ** 17)}.json\"\n",
        "    data.fileName = full_name\n",
        "\n",
        "    with open(f\"{folder}/{full_name}\", \"w\") as write_file:\n",
        "        json.dump(data.__dict__, write_file)\n",
        "\n",
        "\n",
        "# Save json from class\n",
        "def save_json(data, folder: str, file_name: str):\n",
        "    with open(f\"{folder}/{file_name}\", \"w\") as write_file:\n",
        "        json.dump(data.__dict__, write_file)\n",
        "        \n",
        "        \n",
        "# Open json and get parsed dict\n",
        "def open_json(path: str) -> dict:\n",
        "    with open(path) as json_file:\n",
        "      return json.load(json_file)\n",
        "\n",
        "\n",
        "# JSON to Data class\n",
        "def deserialize_json(file_path: str) -> Data:\n",
        "    with open(file_path) as json_file:\n",
        "        data = json.load(json_file)\n",
        "        return Data(data)\n",
        "\n",
        "\n",
        "# JSON to ParsedData class\n",
        "def deserialize_parsed_json(file_path: str) -> ParsedData:\n",
        "    with open(file_path) as json_file:\n",
        "        data = json.load(json_file)\n",
        "        return ParsedData(data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0p_BVRyxGZP",
        "colab_type": "text"
      },
      "source": [
        "# **Work with local files**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aw3r6Auj-dp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distribute(old_folder: str, new_folder: str, parsed: bool):\n",
        "    \"\"\"\n",
        "    Distributes all measurements by activity type, copying to a new folder.\n",
        "    :param old_folder: The folder from which files are taken.\n",
        "    :param new_folder: Folder to which distributed meas. are saved.\n",
        "    :param parsed: Are the points in our dimension divided by the coordinates?\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    \n",
        "    run_folder = f\"{new_folder}/run\"\n",
        "    jump_folder = f\"{new_folder}/jump\"\n",
        "    walk_folder = f\"{new_folder}/walk\"\n",
        "    create_folders([run_folder, jump_folder, walk_folder])\n",
        "    files = list_local_files(old_folder)\n",
        "\n",
        "    for file in files:\n",
        "        data = deserialize_parsed_json(file) if parsed else deserialize_json(file)\n",
        "\n",
        "        if (data.motion['name'].lower() == \"run\"):\n",
        "            copyfile(file, f\"{run_folder}/{data.fileName}\")\n",
        "\n",
        "        if (data.motion['name'].lower() == \"jump\"):\n",
        "            copyfile(file, f\"{jump_folder}/{data.fileName}\")\n",
        "\n",
        "        if (data.motion['name'].lower() == \"walk\"):\n",
        "            copyfile(file, f\"{walk_folder}/{data.fileName}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4HdKQcXMR-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_cut(tmp: Data, cropped_list_x, cropped_list_y, cropped_list_z, folder: str):\n",
        "    \"\"\"\n",
        "    Saving all cut measurements with exactly 300 points.\n",
        "    :param tmp: An object with already cut coordinate lists.\n",
        "    :param cropped_list_x: X-coordinate acceleration list.\n",
        "    :param cropped_list_y: Y-coordinate acceleration list.\n",
        "    :param cropped_list_z: Z-coordinate acceleration list.\n",
        "    :param folder: The path where to save the cropped files.\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    for list_x, list_y, list_z in zip(cropped_list_x, cropped_list_y, cropped_list_z):\n",
        "        if (300 == len(list_x) == len(list_y) == len(list_z)):\n",
        "            cropped_data = CroppedData(tmp.fileName, tmp.motion, tmp.time, tmp.userName, list_x, list_y, list_z)\n",
        "            serialize_json(cropped_data, folder, cropped_data.fileName)\n",
        "\n",
        "\n",
        "def cut_data(folder_path: str, new_folder: str):\n",
        "    \"\"\"\n",
        "    Creating multiple measurements from one, with a given number of points.\n",
        "    :param folder_path: The folder in which the uncut files are stored.\n",
        "    :param new_folder: Folder where to save sliced measurements.\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    files = list_local_files(folder_path)\n",
        "    for file in files:\n",
        "        tmp = deserialize_json(file)\n",
        "        cropped_lists_x = list(sliced(tmp.listX, 300))\n",
        "        cropped_lists_y = list(sliced(tmp.listY, 300))\n",
        "        cropped_lists_z = list(sliced(tmp.listZ, 300))\n",
        "\n",
        "        save_cut(tmp, cropped_lists_x, cropped_lists_y, cropped_lists_z, new_folder)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc4XkqykMR7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mark_up(obj, target_folder, steps: int):\n",
        "    \"\"\"\n",
        "    Forms and saves the marked measurement from obj, sends it to the server.\n",
        "    :param obj: Old unallocated measurements.\n",
        "    :param target_folder: The folder in which to save the marked up measurements.\n",
        "    :param steps: Number of steps.\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    \n",
        "    create_folder(target_folder)\n",
        "    data = MarkedData(obj.fileName, obj.motion, obj.time, obj.userName, obj.listX, obj.listY, obj.listZ, steps)\n",
        "    save_json(data, target_folder, data.fileName)\n",
        "    upload_blob('activitytracker-bde5c.appspot.com', f\"{target_folder}/{data.fileName}\", data.fileName, target_folder)\n",
        "\n",
        "\n",
        "def marking_data(folder_path: str, target_folder: str):\n",
        "    \"\"\"\n",
        "    Iterates over each file, draws a graph and asks for the number of steps.\n",
        "    :param folder_path: The folder in which the unlabeled data is located.\n",
        "    :param target_folder: The folder in which to save the data.\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "\n",
        "    for file in list_local_files(folder_path):\n",
        "        parsed_data = deserialize_parsed_json(file)\n",
        "        title = f\"{parsed_data.userName} - {parsed_data.motion['name']}\"\n",
        "        x = parsed_data.listX\n",
        "        y = parsed_data.listY\n",
        "        z = parsed_data.listZ\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.figure(1)\n",
        "        plt.title(title)\n",
        "        plt.subplot(111)\n",
        "        plt.plot(x)\n",
        "        plt.ylim(-1000, 1000)\n",
        "        plt.subplot(111)\n",
        "        plt.plot(y)\n",
        "        plt.ylim(-1000, 1000)\n",
        "        plt.subplot(111)\n",
        "        plt.plot(z)\n",
        "        plt.ylim(-1000, 1000)\n",
        "        plt.show()\n",
        "        steps = int(input(\"Count steps: \"))\n",
        "        mark_up(parsed_data, file, target_folder, steps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6FSGaMQqPD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def balance_classes(target_folder: str):\n",
        "    \"\"\"\n",
        "    Keeps an equal number of measurements for each class.\n",
        "    :param target_folder: The path to save a balanced dataset.\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "\n",
        "    if os.path.exists(target_folder):\n",
        "      rmtree(target_folder)\n",
        "\n",
        "    create_folder(target_folder)\n",
        "\n",
        "\n",
        "    list_walk = list_local_files(\"google-cloud/dataset-cut-parted/walk\")\n",
        "    list_jump = list_local_files(\"google-cloud/dataset-cut-parted/jump\")\n",
        "    list_run = list_local_files(\"google-cloud/dataset-cut-parted/run\")\n",
        "\n",
        "    min_len = min(len(list_walk), len(list_jump), len(list_run))\n",
        "    print(f\"Min: {min_len}\")\n",
        "    list_files = list_walk[:min_len] + list_jump[:min_len] + list_run[:min_len]\n",
        "\n",
        "    print(f\"Walk: {len(list_walk)}\")\n",
        "    print(f\"Jump: {len(list_jump)}\")\n",
        "    print(f\"Run: {len(list_run)}\")\n",
        "    print(f\"Balanced dataset: {len(list_files)}\")\n",
        "    for file in list_files:\n",
        "        data = deserialize_parsed_json(file)\n",
        "        copyfile(file, f\"{target_folder}/{data.fileName}\")\n",
        "   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KCiyMhlxbfa",
        "colab_type": "text"
      },
      "source": [
        "#**Loading and balancing dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WzpQlnBsA2n",
        "colab_type": "code",
        "outputId": "a587f5b7-0d0e-46e9-86f9-a318e7805f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "# Download all file from FireBase\n",
        "list_blobs = get_blobs('activitytracker-bde5c.appspot.com', \"measurements\")\n",
        "download_blobs(list_blobs, \"google-cloud/measurements\")\n",
        "\n",
        "# Distribute by motions\n",
        "distribute(\"google-cloud/measurements\", \"google-cloud/dataset\", False)\n",
        "\n",
        "# Cropping Data and distribute\n",
        "cut_data(\"google-cloud/measurements\", \"google-cloud/dataset-cut\")\n",
        "distribute(\"google-cloud/dataset-cut\", \"google-cloud/dataset-cut-parted\", True)\n",
        "\n",
        "# Balance the number of measurements in each class\n",
        "balance_classes(\"google-cloud/dataset-cut-balanced\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min: 134\n",
            "Walk: 867\n",
            "Jump: 134\n",
            "Run: 134\n",
            "Balanced dataset: 402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRwh_1-W0dOJ",
        "colab_type": "text"
      },
      "source": [
        "# **Data preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F6Me1ehmith",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parses class names into a binary representation.\n",
        "def mark_motion(name: str) -> list:\n",
        "    run = [0, 0, 1]\n",
        "    jump = [0, 1, 0]\n",
        "    walk = [1, 0, 0]\n",
        "\n",
        "    if (name.lower() == \"run\"):\n",
        "        return run\n",
        "    elif (name.lower() == \"jump\"):\n",
        "        return jump\n",
        "    elif (name.lower() == \"walk\"):\n",
        "        return walk\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz_v8IsjC_z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn three axes into one using L2 Norm\n",
        "def approximation(list_x, list_y, list_z) -> list:\n",
        "    result = np.zeros(300)\n",
        "    for i in range(0, len(list_x)):\n",
        "        result[i] = math.sqrt(list_x[i] ** 2 + list_y[i] ** 2 + list_z[i] ** 2)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRT73xTqrV8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X and y (target) loading for dataset from folder\n",
        "def load_dataset(folder: str):\n",
        "  files = list_local_files(folder)\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(0, len(files)):\n",
        "    data = open_json(files[i])\n",
        "    result = approximation(data['listX'], data['listY'], data['listZ'])\n",
        "    x.append(result)\n",
        "    y.append(mark_motion(data['motion']['name']))\n",
        "  x = np.array(x)\n",
        "  x = np.reshape(x, (x.shape[0], x.shape[1], 1))\n",
        "  y = np.array(y)\n",
        "  return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNgiaOSC0sRo",
        "colab_type": "text"
      },
      "source": [
        "# **Model training - LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmvt_lcAxsio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_dataset():\n",
        "  X, y = load_dataset(\"google-cloud/dataset-cut-balanced\")\n",
        "  return train_test_split(X, y, test_size=0.33, random_state=91)\n",
        "\n",
        "X_train, X_test, y_train, y_test = split_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9nT_C9R9fWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "  def __init__(self, learning_rate, n_timesteps, n_features, n_outputs):\n",
        "    self.model = Sequential()\n",
        "    self.model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
        "    self.model.add(Dropout(0.5))\n",
        "#     self.model.add(Conv1D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
        "#     self.model.add(Dropout(0.5))\n",
        "#     self.model.add(Flatten())\n",
        "    self.model.add(Dense(100, activation='relu'))\n",
        "    self.model.add(Dropout(0.5))\n",
        "    self.model.add(Dense(100, activation='relu'))\n",
        "    self.model.add(Dropout(0.5))\n",
        "    self.model.add(Dense(n_outputs, activation='softmax'))\n",
        "    self.model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=learning_rate), metrics=['accuracy'])\n",
        "  \n",
        "  def get_model(self):\n",
        "    return self.model\n",
        "  def get_summary(self):\n",
        "    return self.model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MannPYZdGcvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from tensorflow.python.tools import freeze_graph\n",
        "from tensorflow.python.tools import optimize_for_inference_lib\n",
        "\n",
        "\n",
        "def export_model(saver, input_names, output_names, model_name='mnist_convnet'):\n",
        "    tf.train.write_graph(K.get_session().graph_def, 'out',\n",
        "                         model_name + '_graph.pbtxt')\n",
        "\n",
        "    saver.save(K.get_session(), 'out/' + model_name + '.chkp')\n",
        "\n",
        "    freeze_graph.freeze_graph('out/' + model_name + '_graph.pbtxt', None,\n",
        "                              False, 'out/' + model_name + '.chkp', output_names[0],\n",
        "                              \"save/restore_all\", \"save/Const:0\",\n",
        "                              'out/frozen_' + model_name + '.pb', True, \"\")\n",
        "\n",
        "    input_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.Open('out/frozen_' + model_name + '.pb', \"rb\") as f:\n",
        "        input_graph_def.ParseFromString(f.read())\n",
        "\n",
        "    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
        "        input_graph_def, input_names, output_names,\n",
        "        tf.float32.as_datatype_enum)\n",
        "\n",
        "    with tf.gfile.FastGFile('out/opt_' + model_name + '.pb', \"wb\") as f:\n",
        "        f.write(output_graph_def.SerializeToString())\n",
        "\n",
        "    print(\"graph saved!\")\n",
        "    \n",
        "export_model(tf.train.Saver(), [\"lstm_6_input\"], [\"dense_9/Softmax\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYcMV5wqW_Ih",
        "colab_type": "code",
        "outputId": "8d3da64b-67f7-4008-f07f-b2d5c1b4340f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "from tensorflow import lite\n",
        "converter = lite.TFLiteConverter.from_keras_model_file('2019-08-22_13_21_30 (1).h5')\n",
        "tfmodel = converter.convert()\n",
        "open(\"model.tflite\" , \"wb\").write(tfmodel)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8155ca6b058e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2019-08-22_13_21_30 (1).h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtfmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.tflite\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_keras_model_file\u001b[0;34m(cls, model_file, input_arrays, input_shapes, output_arrays, custom_objects)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0m_set_tensor_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m     \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_freeze_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/util.py\u001b[0m in \u001b[0;36mfreeze_graph\u001b[0;34m(sess, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0moutput_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_tensor_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     return tf_graph_util.convert_variables_to_constants(sess, graph_def,\n\u001b[0;32m--> 238\u001b[0;31m                                                         output_arrays)\n\u001b[0m\u001b[1;32m    239\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py\u001b[0m in \u001b[0;36mconvert_variables_to_constants\u001b[0;34m(sess, input_graph_def, output_node_names, variable_names_whitelist, variable_names_blacklist)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0msource_op_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_name_to_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource_op_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmap_name_to_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource_op_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"VarHandleOp\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         raise ValueError(\"Cannot find the variable that is an input \"\n\u001b[0m\u001b[1;32m    303\u001b[0m                          \"to the ReadVariableOp.\")\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot find the variable that is an input to the ReadVariableOp."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA-hr9CTYWhq",
        "colab_type": "code",
        "outputId": "2241d74f-06af-4a89-8126-bccf62c31074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.4)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (41.1.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.15.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpJoSgazORkM",
        "colab_type": "code",
        "outputId": "ad90af75-b18b-4377-c280-c8d58341d776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "model = load_model(\"2019-08-22_13_21_30 (1).h5\")\n",
        "model.summary()\n",
        "print(model.layers[0].name)\n",
        "sess = K.get_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_6 (LSTM)                (None, 300, 100)          40800     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 300, 100)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 300, 32)           9632      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 300, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 300, 16)           1552      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 4800)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 100)               480100    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 542,487\n",
            "Trainable params: 542,487\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "lstm_6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxj2t3VNPz7X",
        "colab_type": "code",
        "outputId": "19be288e-a9bd-4257-e0ac-083eaec6d68f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sess.graph"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.framework.ops.Graph at 0x7f73fc890ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjfzMNqtKDW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
        "    \"\"\"\n",
        "    Freezes the state of a session into a pruned computation graph.\n",
        "\n",
        "    Creates a new computation graph where variable nodes are replaced by\n",
        "    constants taking their current value in the session. The new graph will be\n",
        "    pruned so subgraphs that are not necessary to compute the requested\n",
        "    outputs are removed.\n",
        "    @param session The TensorFlow session to be frozen.\n",
        "    @param keep_var_names A list of variable names that should not be frozen,\n",
        "                          or None to freeze all the variables in the graph.\n",
        "    @param output_names Names of the relevant graph outputs.\n",
        "    @param clear_devices Remove the device directives from the graph for better portability.\n",
        "    @return The frozen graph definition.\n",
        "    \"\"\"\n",
        "    graph = session.graph\n",
        "    with graph.as_default():\n",
        "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
        "        output_names = output_names or []\n",
        "        output_names += [v.op.name for v in tf.global_variables()]\n",
        "        input_graph_def = graph.as_graph_def()\n",
        "        if clear_devices:\n",
        "            for node in input_graph_def.node:\n",
        "                node.device = ''\n",
        "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
        "            session, input_graph_def, output_names, freeze_var_names)\n",
        "        return frozen_graph\n",
        "\n",
        "X = np.array([[0,0], [0,1], [1,0], [1,1]], 'float32')\n",
        "Y = np.array([[0], [1], [1], [0]], 'float32')\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(64, input_dim=2, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])\n",
        "\n",
        "model.fit(X, Y, batch_size=1, nb_epoch=100, verbose=0)\n",
        "\n",
        "# inputs:  ['dense_input']\n",
        "print('inputs: ', [input.op.name for input in model.inputs])\n",
        "\n",
        "# outputs:  ['dense_4/Sigmoid']\n",
        "print('outputs: ', [output.op.name for output in model.outputs])\n",
        "\n",
        "model.save('./xor.h5')\n",
        "\n",
        "frozen_graph = freeze_session(tf.keras.backend.get_session(), output_names=[out.op.name for out in model.outputs])\n",
        "tf.train.write_graph(frozen_graph, './', 'xor.pbtxt', as_text=True)\n",
        "tf.train.write_graph(frozen_graph, './', 'xor.pb', as_text=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxQYgK_Atjgu",
        "colab_type": "code",
        "outputId": "ea1e0d9f-b754-4ad5-af9d-a7f8d65cf7fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "custom_model = Model(0.001, 300, 1, 3)\n",
        "# lstm model\n",
        "# fit and evaluate a model\n",
        "def evaluate_model(trainX, trainy, testX, testy):\n",
        "  print(trainX.shape, trainy.shape)\n",
        "  n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "  \n",
        "  # comile network\n",
        "  model = custom_model.get_model()\n",
        "  \n",
        "  # fit network\n",
        "  history = model.fit(trainX, trainy, epochs=300, validation_split=0.2, shuffle=True)\n",
        "  \n",
        "  # graphics   \n",
        "  f = plt.figure(figsize=(20,6))\n",
        "  acc = f.add_subplot(121)\n",
        "  loss = f.add_subplot(122)\n",
        "  acc.plot(history.history['acc'])\n",
        "  acc.plot(history.history['val_acc'])\n",
        "  acc.set_title('model accuracy')\n",
        "  acc.set_ylabel('accuracy')\n",
        "  acc.set_xlabel('epoch')\n",
        "  acc.legend(['train', 'val'], loc='upper left')\n",
        "  loss.plot(history.history['loss'])\n",
        "  loss.plot(history.history['val_loss'])\n",
        "  loss.set_title('model loss')\n",
        "  loss.set_ylabel('loss')\n",
        "  loss.set_xlabel('epoch')\n",
        "  \n",
        "  plt.show()\n",
        "\n",
        "  \n",
        "  # evaluate model and save\n",
        "  _, accuracy = model.evaluate(testX, testy, verbose=0)\n",
        "  round_acc = int(accuracy*100) \n",
        "  model.save(f\"{round_acc}_{datetime.now().strftime('%m-%d_%H:%M:%S')}.h5\")\n",
        "  return accuracy\n",
        "\n",
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "\tprint(scores)\n",
        "\tm, s = mean(scores), std(scores)\n",
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        "\n",
        "# run an experiment\n",
        "def run_experiment(repeats, X_tr, X_te, y_tr, y_te):\n",
        "  \n",
        "  # repeat experiment\n",
        "  scores = list()\n",
        "  for repeat in range(repeats):\n",
        "    score = evaluate_model(X_tr, y_tr, X_te, y_te)\n",
        "    score = score * 100.0\n",
        "    print('>#%d: %.3f' % (repeat+1, score))\n",
        "    scores.append(score)\n",
        "    \n",
        "  # summarize results\n",
        "  summarize_results(scores)\n",
        "\n",
        "# run the experiment\n",
        "run_experiment(3, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(269, 300, 1) (269, 3)\n",
            "Train on 215 samples, validate on 54 samples\n",
            "Epoch 1/300\n",
            "215/215 [==============================] - 7s 31ms/step - loss: 1.2430 - acc: 0.3395 - val_loss: 1.0890 - val_acc: 0.4259\n",
            "Epoch 2/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 1.2470 - acc: 0.3256 - val_loss: 1.0790 - val_acc: 0.3519\n",
            "Epoch 3/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 1.2122 - acc: 0.3442 - val_loss: 1.0566 - val_acc: 0.3519\n",
            "Epoch 4/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 1.1206 - acc: 0.4372 - val_loss: 1.0281 - val_acc: 0.3519\n",
            "Epoch 5/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 1.1428 - acc: 0.3953 - val_loss: 0.9906 - val_acc: 0.4259\n",
            "Epoch 6/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 1.0348 - acc: 0.4651 - val_loss: 0.9627 - val_acc: 0.4815\n",
            "Epoch 7/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 1.0282 - acc: 0.4698 - val_loss: 0.9338 - val_acc: 0.6111\n",
            "Epoch 8/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 1.0173 - acc: 0.5116 - val_loss: 0.9179 - val_acc: 0.4815\n",
            "Epoch 9/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 1.0398 - acc: 0.4419 - val_loss: 0.9008 - val_acc: 0.4815\n",
            "Epoch 10/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.9489 - acc: 0.5256 - val_loss: 0.8738 - val_acc: 0.4815\n",
            "Epoch 11/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.9528 - acc: 0.5163 - val_loss: 0.8556 - val_acc: 0.4815\n",
            "Epoch 12/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.9296 - acc: 0.5209 - val_loss: 0.8448 - val_acc: 0.5185\n",
            "Epoch 13/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8804 - acc: 0.5674 - val_loss: 0.8299 - val_acc: 0.6111\n",
            "Epoch 14/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.9663 - acc: 0.5023 - val_loss: 0.8177 - val_acc: 0.6296\n",
            "Epoch 15/300\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.9439 - acc: 0.5163 - val_loss: 0.8054 - val_acc: 0.6296\n",
            "Epoch 16/300\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.8894 - acc: 0.5535 - val_loss: 0.8121 - val_acc: 0.6481\n",
            "Epoch 17/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8728 - acc: 0.5581 - val_loss: 0.8188 - val_acc: 0.6481\n",
            "Epoch 18/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.9695 - acc: 0.5209 - val_loss: 0.8143 - val_acc: 0.6296\n",
            "Epoch 19/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8021 - acc: 0.5907 - val_loss: 0.7876 - val_acc: 0.5926\n",
            "Epoch 20/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8269 - acc: 0.5442 - val_loss: 0.7860 - val_acc: 0.6296\n",
            "Epoch 21/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8988 - acc: 0.5860 - val_loss: 0.7705 - val_acc: 0.6296\n",
            "Epoch 22/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8798 - acc: 0.5395 - val_loss: 0.7865 - val_acc: 0.6296\n",
            "Epoch 23/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7941 - acc: 0.6000 - val_loss: 0.7606 - val_acc: 0.6296\n",
            "Epoch 24/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8047 - acc: 0.6000 - val_loss: 0.7415 - val_acc: 0.6296\n",
            "Epoch 25/300\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.8463 - acc: 0.5349 - val_loss: 0.8147 - val_acc: 0.6111\n",
            "Epoch 26/300\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.8366 - acc: 0.5907 - val_loss: 0.7244 - val_acc: 0.6481\n",
            "Epoch 27/300\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.7996 - acc: 0.5814 - val_loss: 0.7321 - val_acc: 0.6667\n",
            "Epoch 28/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8194 - acc: 0.6233 - val_loss: 0.7698 - val_acc: 0.6481\n",
            "Epoch 29/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8224 - acc: 0.6140 - val_loss: 0.7096 - val_acc: 0.7222\n",
            "Epoch 30/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7706 - acc: 0.6326 - val_loss: 0.7331 - val_acc: 0.6852\n",
            "Epoch 31/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7471 - acc: 0.6140 - val_loss: 0.7048 - val_acc: 0.6852\n",
            "Epoch 32/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8238 - acc: 0.6140 - val_loss: 0.8374 - val_acc: 0.5741\n",
            "Epoch 33/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8141 - acc: 0.6372 - val_loss: 0.6854 - val_acc: 0.6852\n",
            "Epoch 34/300\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.7871 - acc: 0.5860 - val_loss: 0.7164 - val_acc: 0.7037\n",
            "Epoch 35/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8195 - acc: 0.6372 - val_loss: 0.7254 - val_acc: 0.6667\n",
            "Epoch 36/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8037 - acc: 0.6512 - val_loss: 0.7150 - val_acc: 0.6667\n",
            "Epoch 37/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8067 - acc: 0.5907 - val_loss: 0.7097 - val_acc: 0.6481\n",
            "Epoch 38/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8116 - acc: 0.6186 - val_loss: 0.7209 - val_acc: 0.7222\n",
            "Epoch 39/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7329 - acc: 0.6233 - val_loss: 0.7102 - val_acc: 0.7222\n",
            "Epoch 40/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7160 - acc: 0.6744 - val_loss: 0.6906 - val_acc: 0.6852\n",
            "Epoch 41/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7163 - acc: 0.6558 - val_loss: 0.6697 - val_acc: 0.7222\n",
            "Epoch 42/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7306 - acc: 0.6744 - val_loss: 0.6894 - val_acc: 0.6667\n",
            "Epoch 43/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.8007 - acc: 0.6279 - val_loss: 0.6972 - val_acc: 0.6852\n",
            "Epoch 44/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7823 - acc: 0.6279 - val_loss: 0.6639 - val_acc: 0.6852\n",
            "Epoch 45/300\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.7048 - acc: 0.6512 - val_loss: 0.6852 - val_acc: 0.6852\n",
            "Epoch 46/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7704 - acc: 0.6372 - val_loss: 0.6742 - val_acc: 0.7037\n",
            "Epoch 47/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7275 - acc: 0.6372 - val_loss: 0.6875 - val_acc: 0.6852\n",
            "Epoch 48/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7330 - acc: 0.6233 - val_loss: 0.6967 - val_acc: 0.6852\n",
            "Epoch 49/300\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.7286 - acc: 0.6279 - val_loss: 0.6871 - val_acc: 0.6852\n",
            "Epoch 50/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7431 - acc: 0.6930 - val_loss: 0.7064 - val_acc: 0.6667\n",
            "Epoch 51/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7030 - acc: 0.6233 - val_loss: 0.6950 - val_acc: 0.6852\n",
            "Epoch 52/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.6885 - acc: 0.6698 - val_loss: 0.7409 - val_acc: 0.6296\n",
            "Epoch 53/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7348 - acc: 0.6372 - val_loss: 0.6643 - val_acc: 0.7037\n",
            "Epoch 54/300\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.6639 - acc: 0.6698 - val_loss: 0.6815 - val_acc: 0.6667\n",
            "Epoch 55/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.6554 - acc: 0.6465 - val_loss: 0.6791 - val_acc: 0.6667\n",
            "Epoch 56/300\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.7070 - acc: 0.6558 - val_loss: 0.6572 - val_acc: 0.6852\n",
            "Epoch 57/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.6813 - acc: 0.6372 - val_loss: 0.7209 - val_acc: 0.6296\n",
            "Epoch 58/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7057 - acc: 0.6372 - val_loss: 0.6596 - val_acc: 0.6852\n",
            "Epoch 59/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.6858 - acc: 0.6884 - val_loss: 0.6646 - val_acc: 0.6852\n",
            "Epoch 60/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7046 - acc: 0.6651 - val_loss: 0.6689 - val_acc: 0.6852\n",
            "Epoch 61/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.6192 - acc: 0.6977 - val_loss: 0.6650 - val_acc: 0.7222\n",
            "Epoch 62/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.6731 - acc: 0.6605 - val_loss: 0.6549 - val_acc: 0.7407\n",
            "Epoch 63/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7223 - acc: 0.6605 - val_loss: 0.6645 - val_acc: 0.7407\n",
            "Epoch 64/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.7409 - acc: 0.6605 - val_loss: 0.6648 - val_acc: 0.7037\n",
            "Epoch 65/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.6545 - acc: 0.6837 - val_loss: 0.6499 - val_acc: 0.7037\n",
            "Epoch 66/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.6715 - acc: 0.7023 - val_loss: 0.6999 - val_acc: 0.6667\n",
            "Epoch 67/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.6818 - acc: 0.7628 - val_loss: 0.6573 - val_acc: 0.7407\n",
            "Epoch 68/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.6958 - acc: 0.6651 - val_loss: 0.6520 - val_acc: 0.7407\n",
            "Epoch 69/300\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.6896 - acc: 0.6651 - val_loss: 0.6488 - val_acc: 0.7407\n",
            "Epoch 70/300\n",
            "128/215 [================>.............] - ETA: 1s - loss: 0.6456 - acc: 0.7500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-0decf88df175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# run the experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-0decf88df175>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(repeats, X_tr, X_te, y_tr, y_te)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mrepeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>#%d: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-0decf88df175>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(trainX, trainy, testX, testy)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# fit network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# graphics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IZBFhWQw6aK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, testX, testy):\n",
        "  _, accuracy = model.evaluate(testX, testy, verbose=1)\n",
        "  return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atxF-NmasD_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj_dFZyp4xRV",
        "colab_type": "code",
        "outputId": "281830bb-043d-4e1b-e96a-1b841f7a4fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "test_model(load_model(\"90_08-23_03:51:48.h5\"), X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1112\u001b[0m             subfeed_t = self.graph.as_graph_element(\n\u001b[0;32m-> 1113\u001b[0;31m                 subfeed, allow_tensor=True, allow_operation=False)\n\u001b[0m\u001b[1;32m   1114\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3795\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3796\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3874\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3875\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3876\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Placeholder_63:0\", shape=(1, 400), dtype=float32) is not an element of this graph.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-2fdc3c8ac587>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"90_08-23_03:51:48.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(f, custom_objects, compile)\u001b[0m\n\u001b[1;32m    285\u001b[0m                              ' elements.')\n\u001b[1;32m    286\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2468\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1114\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             raise TypeError(\n\u001b[0;32m-> 1116\u001b[0;31m                 'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder_63:0\", shape=(1, 400), dtype=float32) is not an element of this graph."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXDMMW5GPHQe",
        "colab_type": "code",
        "outputId": "4ace750d-430b-4d1c-8c14-bcd558141d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "load_model(\"90_08-23_03:51:48.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1112\u001b[0m             subfeed_t = self.graph.as_graph_element(\n\u001b[0;32m-> 1113\u001b[0;31m                 subfeed, allow_tensor=True, allow_operation=False)\n\u001b[0m\u001b[1;32m   1114\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3795\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3796\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3874\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3875\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3876\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Placeholder_72:0\", shape=(1, 400), dtype=float32) is not an element of this graph.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-f889376ef391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"90_08-23_03:51:48.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(f, custom_objects, compile)\u001b[0m\n\u001b[1;32m    285\u001b[0m                              ' elements.')\n\u001b[1;32m    286\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2468\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2469\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1114\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             raise TypeError(\n\u001b[0;32m-> 1116\u001b[0;31m                 'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder_72:0\", shape=(1, 400), dtype=float32) is not an element of this graph."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djfaMpQI05gz",
        "colab_type": "text"
      },
      "source": [
        "# **Delete all data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFdCikisZD94",
        "colab_type": "code",
        "outputId": "ced3a4ea-1375-49e5-aa99-018711593285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "check = input(\"Press F to delete all data: \")\n",
        "\n",
        "rmtree('google-cloud') if check == \"F\" else print(\"I need to get away!\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Press F to delete all data: F\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BcKXXVm3pXn",
        "colab_type": "text"
      },
      "source": [
        "# **Predict classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvoNmN4b3ti7",
        "colab_type": "code",
        "outputId": "cf45b809-03d1-474a-fa47-9bd2219496c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "X, y = load_dataset(\"test-jump\")\n",
        "ynew = model.predict_classes(X)\n",
        "# show the inputs and predicted outputs\n",
        "for res in ynew:\n",
        "  print(\"Predicted=%s\" % res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted=2\n",
            "Predicted=2\n",
            "Predicted=1\n",
            "Predicted=1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzTrO2ZQN6Xq",
        "colab_type": "text"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMOfQZAmLxp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def confusion_matrix(model, n_classes=3):\n",
        "  X, y = load_dataset(\"google-cloud/dataset-cut-balanced\")\n",
        "  assert X.shape[0] == y.shape[0]\n",
        "  assert n_classes == y.shape[1]\n",
        "  confusion = np.zeros((n_classes, n_classes))\n",
        "  \n",
        "  for k in tqdm(range(X.shape[0])):\n",
        "    y_hat = model.predict(np.expand_dims(X[k], axis=0))\n",
        "    predicted = np.argmax(y_hat[0])\n",
        "    correct = np.argmax(y[k])\n",
        "    confusion[correct][predicted] += 1.\n",
        "    \n",
        "    \n",
        "  df_cm = pd.DataFrame(confusion, index = [\"Walk\",\"Jump\", \"Run\"], columns = [\"Walk\",\"Jump\", \"Run\"])\n",
        "  plt.figure(figsize = (10,7))\n",
        "  sn.heatmap(df_cm, annot=True)\n",
        "  plt.xlabel(\"Predicted\")\n",
        "  plt.ylabel(\"Correct\")\n",
        "\n",
        "    \n",
        "    \n",
        "  return confusion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf__uD3JOLTA",
        "colab_type": "code",
        "outputId": "f3f2cc47-4fd0-4c78-cc7a-a9b05dac117c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "conf_matrix = confusion_matrix(custom_model.get_model())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 402/402 [01:29<00:00,  4.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGtCAYAAAABCu4VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tts50s25RiB3",
        "colab_type": "code",
        "outputId": "90c65a6a-ebbb-43b3-87c8-e12d7f9ca0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "conf_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[125.,   1.,   8.],\n",
              "       [  7., 126.,   1.],\n",
              "       [ 11.,   0., 123.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ_U2GtPoNGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(n_timestamps, n_features, n_classes):\n",
        "  model = Sequential([\n",
        "       LSTM(units=100, input_shape=(n_timestamps, n_features), return_sequences=True),\n",
        "       Dropout(0.5),\n",
        "       Conv1D(filters=64, kernel_size=9, activation='relu', padding='same'),\n",
        "       Dropout(0.5),\n",
        "       Conv1D(filters=16, kernel_size=9, activation='relu', padding='same'),\n",
        "       Dropout(0.5),\n",
        "       Flatten(),\n",
        "       Dense(units=100, activation='relu'),\n",
        "       Dropout(0.5),\n",
        "       Dense(units=n_classes, activation='softmax'),\n",
        "   ])\n",
        "  model.compile(optimizer=Adam(), metrics=['accuracy'], loss='categorical_crossentropy')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}